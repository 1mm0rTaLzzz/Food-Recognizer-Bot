import os
import torch
import torchvision.transforms as transforms
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import CommandStart
from aiogram.fsm.storage.memory import MemoryStorage
from transformers import AutoFeatureExtractor, AutoModelForImageClassification
import numpy as np
import logging
import asyncio

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∞ –∏–∑ .env ===
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")

# === 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_NAME = "nateraw/food"  # –ú–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥—ã

feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)
model = AutoModelForImageClassification.from_pretrained(MODEL_NAME).to(device)
model.eval()

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def preprocess_image(image):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if image.mode != 'RGB':
        image = image.convert('RGB')

    image_tensor = transform(image)
    return image_tensor.unsqueeze(0).to(device)

def get_top_predictions(probs, threshold=0.1):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
    values, indices = torch.topk(probs, k=5)  # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    predictions = []
    for value, idx in zip(values, indices):
        if value.item() > threshold:
            label = model.config.id2label[idx.item()]
            predictions.append((label, value.item()))
    return predictions

# === 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Telegram-–±–æ—Ç–∞ ===
bot = Bot(BOT_TOKEN)
dp = Dispatcher(storage=MemoryStorage())

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –±–ª—é–¥–∞, –∏ —è —Å–∫–∞–∂—É, —á—Ç–æ —ç—Ç–æ –∑–∞ –µ–¥–∞, –∞ —Ç–∞–∫–∂–µ –æ—Ü–µ–Ω—é –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å.\n\n"
        "üí° –°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:\n"
        "‚Ä¢ –°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –±–ª—é–¥–æ –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º –æ—Å–≤–µ—â–µ–Ω–∏–∏\n"
        "‚Ä¢ –°—Ç–∞—Ä–∞–π—Ç–µ—Å—å, —á—Ç–æ–±—ã –±–ª—é–¥–æ –∑–∞–Ω–∏–º–∞–ª–æ –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∫–∞–¥—Ä–∞\n"
        "‚Ä¢ –ò–∑–±–µ–≥–∞–π—Ç–µ —Ä–∞–∑–º—ã—Ç–∏—è –∏ –æ—Ç—Ä–∞–∂–µ–Ω–∏–π"
    )

@dp.message(F.photo)
async def handle_photo(message: types.Message):
    try:
        photo = message.photo[-1]  # –ë–µ—Ä–µ–º —Ñ–æ—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        file = await bot.get_file(photo.file_id)
        buf = BytesIO()
        await bot.download_file(file.file_path, destination=buf)
        buf.seek(0)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.open(buf)
        img_tensor = preprocess_image(img)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = get_top_predictions(probs, threshold=0.1)
        
        if not predictions:
            await message.reply("üòï –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —ç—Ç–æ –∑–∞ –±–ª—é–¥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ –ø—Ä–∏ –ª—É—á—à–µ–º –æ—Å–≤–µ—â–µ–Ω–∏–∏ –∏–ª–∏ —Å –¥—Ä—É–≥–æ–≥–æ —Ä–∞–∫—É—Ä—Å–∞.")
            return

        text = "üçΩ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:\n\n"
        for label, prob in predictions:
            text += f"‚Ä¢ {label}: {prob*100:.1f}%\n"
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        confidence = predictions[0][1]
        base_calories = 250
        max_additional_calories = 350
        est_cal = round(base_calories + max_additional_calories * confidence)
        
        text += f"\nüî• –ü—Ä–∏–º–µ—Ä–Ω–∞—è –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å: ~{est_cal} –∫–∫–∞–ª"
        
        if confidence < 0.5:
            text += "\n\n‚ö†Ô∏è –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –Ω–µ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è. –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ –ø—Ä–∏ –ª—É—á—à–µ–º –æ—Å–≤–µ—â–µ–Ω–∏–∏."
        
        await message.reply(text)
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ: {e}")
        await message.reply("üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(dp.start_polling(bot))
